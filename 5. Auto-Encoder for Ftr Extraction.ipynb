{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5. Auto-Encoder for Ftr Extraction.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMyZlMYXziIzKGUCO+5hJEO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhamscifi/Instacart-Market-Basket-Analysis/blob/main/5.%20Auto-Encoder%20for%20Ftr%20Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddz-BwQy2-S-"
      },
      "source": [
        "# **[Instacart Market Basket Analysis](https://www.kaggle.com/c/instacart-market-basket-analysis/)**\n",
        "\n",
        "---\n",
        "- Given order_id predict all the products that the user will reorder.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g12i9UdRWOwy"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xsk-yqDBXSA"
      },
      "source": [
        "import plotly\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "import re\n",
        "import gc   # garbage collector\n",
        "import pickle\n",
        "# https://pypi.org/project/tqdm/#:~:text=jupyter%20console.%20Use-,auto,-instead%20of%20autonotebook\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn.metrics import f1_score,confusion_matrix,\\\n",
        "                            precision_recall_fscore_support,classification_report,\\\n",
        "                            accuracy_score,log_loss\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "bold = lambda string: '\\033[1m'+string+'\\033[0m'    # for bold text\n",
        "printb = lambda string: print('\\033[1m'+string+'\\033[0m')\n",
        "# https://stackoverflow.com/questions/8924173/how-do-i-print-bold-text-in-python/8930747"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwp2y_BKLOcb"
      },
      "source": [
        "## Kaggle file uploader utility:\n",
        "- To upload intermediate tables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoX8a6WRLOcc"
      },
      "source": [
        "def kaggle_file_uploader(files,id='shubhamscifi/instacart',title='instacart',folder='data',msg='',first_time=False,del_after_upload=True):\n",
        "    '''Uploads list of files to kaggle.\n",
        "    Note: make sure to run after kaggle authentication.\n",
        "    id : must be between 6-50 chars after \"username/\".\n",
        "    title : must be between 6-50 chars.\n",
        "    files : list of path of files that are to be uploaded.\n",
        "    first_time: True if the data is being uploaded for the first time.\n",
        "    del_after_upload: True if given folder needs to be deleted after file upload finishes.'''\n",
        "    # https://github.com/Kaggle/kaggle-api\n",
        "\n",
        "    # create data package json file\n",
        "    !mkdir {folder}\n",
        "    !kaggle datasets init -p {folder}\n",
        "\n",
        "    # preparing metadata json file\n",
        "    import json,os\n",
        "    metadata = open(os.path.join(folder,'dataset-metadata.json'),'r+')\n",
        "    meta = json.load(metadata)\n",
        "    meta['id'] = id\n",
        "    meta['title']= title\n",
        "    metadata.seek(0)\n",
        "    json.dump(meta,metadata)\n",
        "    metadata.truncate()\n",
        "    metadata.close()\n",
        "\n",
        "    for file in set(files):\n",
        "        !cp {file} {folder}\n",
        "\n",
        "    # upload dataset to kaggle\n",
        "    if (first_time):\n",
        "        !kaggle datasets create -p {folder}\n",
        "    else:\n",
        "        # Create a New Dataset Version\n",
        "        !kaggle datasets version -p {folder} -m '{msg}'\n",
        "\n",
        "    if (del_after_upload):\n",
        "        !rm -rf {folder}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4xSz7nZ-Zsu"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6NI3bdOT0-p",
        "outputId": "1be6a6f7-fdb9-45b6-c0d7-b7e6f4624346"
      },
      "source": [
        "# Kaggle authentication\n",
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = \"shubhamscifi\" #input('Enter kaggle username: ') # kaggle username\n",
        "os.environ['KAGGLE_KEY'] = getpass('Enter Token: ') # kaggle api key"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter Token: ··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-Ai4H5e2u6w"
      },
      "source": [
        "**Download intermediate prepared tables.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6zJQKy5twH9",
        "outputId": "7c7adea0-cb08-4f1e-b7f4-e29efbc5bb8f"
      },
      "source": [
        "!kaggle datasets download -d shubhamscifi/instacart --unzip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading instacart.zip to /content\n",
            " 99% 1.46G/1.47G [00:13<00:00, 189MB/s]\n",
            "100% 1.47G/1.47G [00:13<00:00, 113MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MRBg0fBe6mK",
        "outputId": "6e521a14-28af-4da5-9bbf-21d4a79fde7d"
      },
      "source": [
        "%%time\n",
        "dataset = pd.read_feather('dataset.feather')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.92 s, sys: 19.8 s, total: 22.7 s\n",
            "Wall time: 1.35 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7n_Mhwm3DUa"
      },
      "source": [
        "# loading data into pandas dataframe\n",
        "orders = pd.read_csv('/content/orders.csv',dtype={'order_id':np.uint32,\n",
        "                                                  'user_id' :np.uint32,\n",
        "                                                  'order_number':'uint8',\n",
        "                                                  'order_hour_of_day':'uint8',\n",
        "                                                  'order_dow':'uint8',\n",
        "                                                  'days_since_prior_order':'float16'})\n",
        "dep = pd.read_csv('/content/departments.csv', dtype={'department_id':'uint8',\n",
        "                                                     'department': str})\n",
        "aisles = pd.read_csv('/content/aisles.csv', dtype={'aisle_id':'uint8',\n",
        "                                                     'aisle': str})\n",
        "products = pd.read_csv('/content/products.csv', dtype={'aisle_id':'uint8',\n",
        "                                                     'department_id':'uint8',\n",
        "                                                     'product_name': str,\n",
        "                                                     'product_id': np.uint16})\n",
        "order_products_prior = pd.read_csv('/content/order_products__prior.csv',\n",
        "                                   dtype={'add_to_cart_order':'uint8',\n",
        "                                          'reordered':'uint8',\n",
        "                                          'order_id':np.uint32,\n",
        "                                          'product_id':np.uint16})\n",
        "order_products_train = pd.read_csv('/content/order_products__train.csv',\n",
        "                                   dtype={'add_to_cart_order':'uint8',\n",
        "                                          'reordered':'uint8',\n",
        "                                          'order_id':np.uint32,\n",
        "                                          'product_id':np.uint16})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o2ReVNvl8aW"
      },
      "source": [
        "## Feature scaling:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcRdVKt9l8aY"
      },
      "source": [
        "# list of features that are not in the range 0-1.\n",
        "scaling_ftrs = ['#reorders_u', '#purchases_u', '#first_purchases_u',\n",
        "       'mean_#reorders_u', 'median_#reorders_u', 'min_#reorders_u', 'max_#reorders_u',\n",
        "       'mean_#purchases_u', 'median_#purchases_u', 'min_#purchases_u', 'max_#purchases_u', \n",
        "       'mean_#first_purchases_u', 'median_#first_purchases_u', 'min_#first_purchases_u', \n",
        "       'max_#first_purchases_u', '#avg_reorders_dep', '#avg_reorders_aisle', '#reorders_p',\n",
        "       '#purchases_p', '#first_purchases_p', '#reorders_up']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x09PUj8Nl8ab",
        "outputId": "16138900-3b75-4e7c-94bd-8591806ab64a"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# feature scaling\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(dataset.loc[dataset.eval_set=='train',scaling_ftrs])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler(copy=True, feature_range=(0, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "7XZtifHrl8af",
        "outputId": "5ddef28d-4eb3-4bea-885d-317b74102eaf"
      },
      "source": [
        "dataset[scaling_ftrs] = (\n",
        "    scaler.transform(dataset[scaling_ftrs])\n",
        ")\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>order_id</th>\n",
              "      <th>eval_set</th>\n",
              "      <th>reordered</th>\n",
              "      <th>#reorders_u</th>\n",
              "      <th>#purchases_u</th>\n",
              "      <th>#first_purchases_u</th>\n",
              "      <th>p(reorder|user)</th>\n",
              "      <th>mean_#reorders</th>\n",
              "      <th>median_#reorders</th>\n",
              "      <th>min_#reorders</th>\n",
              "      <th>max_#reorders</th>\n",
              "      <th>mean_#purchases</th>\n",
              "      <th>median_#purchases</th>\n",
              "      <th>min_#purchases</th>\n",
              "      <th>max_#purchases</th>\n",
              "      <th>mean_#first_purchases</th>\n",
              "      <th>median_#first_purchases</th>\n",
              "      <th>min_#first_purchases</th>\n",
              "      <th>max_#first_purchases</th>\n",
              "      <th>mean_p(reorder|user,order)</th>\n",
              "      <th>median_p(reorder|user,order)</th>\n",
              "      <th>min_p(reorder|user,order)</th>\n",
              "      <th>max_p(reorder|user,order)</th>\n",
              "      <th>dep_target_enc</th>\n",
              "      <th>aisle_target_enc</th>\n",
              "      <th>eatable</th>\n",
              "      <th>#avg_reorders_dep</th>\n",
              "      <th>p(reorder|dep_of_prod)</th>\n",
              "      <th>#avg_reorders_aisle</th>\n",
              "      <th>p(reorder|aisle_of_prod)</th>\n",
              "      <th>#reorders_p</th>\n",
              "      <th>#purchases_p</th>\n",
              "      <th>#first_purchases_p</th>\n",
              "      <th>p(reorder|product)</th>\n",
              "      <th>#reorders_up</th>\n",
              "      <th>p(reorder|user,product)</th>\n",
              "      <th>reordered_in_last_order</th>\n",
              "      <th>reordered_in_2ndlast_order</th>\n",
              "      <th>reordered_in_3rdlast_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>13176</td>\n",
              "      <td>1492625</td>\n",
              "      <td>train</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.035002</td>\n",
              "      <td>0.062786</td>\n",
              "      <td>0.13931</td>\n",
              "      <td>0.476923</td>\n",
              "      <td>0.153297</td>\n",
              "      <td>0.191489</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137255</td>\n",
              "      <td>0.183962</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.072727</td>\n",
              "      <td>0.173611</td>\n",
              "      <td>0.144637</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.028571</td>\n",
              "      <td>0.097561</td>\n",
              "      <td>0.482419</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.128464</td>\n",
              "      <td>0.169311</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.649913</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.718104</td>\n",
              "      <td>0.792539</td>\n",
              "      <td>0.802958</td>\n",
              "      <td>0.859117</td>\n",
              "      <td>0.832555</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>41787</td>\n",
              "      <td>1492625</td>\n",
              "      <td>train</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.035002</td>\n",
              "      <td>0.062786</td>\n",
              "      <td>0.13931</td>\n",
              "      <td>0.476923</td>\n",
              "      <td>0.153297</td>\n",
              "      <td>0.191489</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137255</td>\n",
              "      <td>0.183962</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.072727</td>\n",
              "      <td>0.173611</td>\n",
              "      <td>0.144637</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.028571</td>\n",
              "      <td>0.097561</td>\n",
              "      <td>0.482419</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.128464</td>\n",
              "      <td>0.169311</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.649913</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.718104</td>\n",
              "      <td>0.057738</td>\n",
              "      <td>0.074936</td>\n",
              "      <td>0.167629</td>\n",
              "      <td>0.649903</td>\n",
              "      <td>0.010309</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>32792</td>\n",
              "      <td>1492625</td>\n",
              "      <td>train</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.035002</td>\n",
              "      <td>0.062786</td>\n",
              "      <td>0.13931</td>\n",
              "      <td>0.476923</td>\n",
              "      <td>0.153297</td>\n",
              "      <td>0.191489</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137255</td>\n",
              "      <td>0.183962</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.072727</td>\n",
              "      <td>0.173611</td>\n",
              "      <td>0.144637</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.028571</td>\n",
              "      <td>0.097561</td>\n",
              "      <td>0.482419</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.088779</td>\n",
              "      <td>0.098166</td>\n",
              "      <td>1</td>\n",
              "      <td>0.066800</td>\n",
              "      <td>0.574180</td>\n",
              "      <td>0.043716</td>\n",
              "      <td>0.591986</td>\n",
              "      <td>0.001984</td>\n",
              "      <td>0.002897</td>\n",
              "      <td>0.007816</td>\n",
              "      <td>0.577372</td>\n",
              "      <td>0.082474</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>47766</td>\n",
              "      <td>1492625</td>\n",
              "      <td>train</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.035002</td>\n",
              "      <td>0.062786</td>\n",
              "      <td>0.13931</td>\n",
              "      <td>0.476923</td>\n",
              "      <td>0.153297</td>\n",
              "      <td>0.191489</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137255</td>\n",
              "      <td>0.183962</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.072727</td>\n",
              "      <td>0.173611</td>\n",
              "      <td>0.144637</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.028571</td>\n",
              "      <td>0.097561</td>\n",
              "      <td>0.482419</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.128464</td>\n",
              "      <td>0.169311</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.649913</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.718104</td>\n",
              "      <td>0.336279</td>\n",
              "      <td>0.374159</td>\n",
              "      <td>0.578325</td>\n",
              "      <td>0.758103</td>\n",
              "      <td>0.030928</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>20574</td>\n",
              "      <td>1492625</td>\n",
              "      <td>train</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.035002</td>\n",
              "      <td>0.062786</td>\n",
              "      <td>0.13931</td>\n",
              "      <td>0.476923</td>\n",
              "      <td>0.153297</td>\n",
              "      <td>0.191489</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137255</td>\n",
              "      <td>0.183962</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.072727</td>\n",
              "      <td>0.173611</td>\n",
              "      <td>0.144637</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.028571</td>\n",
              "      <td>0.097561</td>\n",
              "      <td>0.482419</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.104139</td>\n",
              "      <td>0.104603</td>\n",
              "      <td>1</td>\n",
              "      <td>0.126903</td>\n",
              "      <td>0.607719</td>\n",
              "      <td>0.092866</td>\n",
              "      <td>0.606517</td>\n",
              "      <td>0.019121</td>\n",
              "      <td>0.021572</td>\n",
              "      <td>0.034778</td>\n",
              "      <td>0.747621</td>\n",
              "      <td>0.010309</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  product_id  ...  reordered_in_2ndlast_order reordered_in_3rdlast_order\n",
              "0        2       13176  ...                           0                          0\n",
              "1        2       41787  ...                           0                          0\n",
              "2        2       32792  ...                           0                          1\n",
              "3        2       47766  ...                           0                          0\n",
              "4        2       20574  ...                           0                          0\n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzxPQU-Ki2gm"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRgtrbISgB9W"
      },
      "source": [
        "## Feature Extraction using **Denoising Auto-encoder**:\n",
        "- To get non-linear relationships from the data.\n",
        "- Denoising makes Auto-encoder more robust and prevent it from over-fitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NW8PgAy_sZXW",
        "outputId": "ecc2b38a-26e5-4432-c388-fc1f5a562c43"
      },
      "source": [
        "#importing tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense,Input,InputLayer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXFXm9h2y7oV"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random as rn\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "\n",
        "##https://keras.io/getting-started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\n",
        "## Have to clear the session. If you are not clearing, Graph will create again and again and graph size will increses. \n",
        "## Varibles will also set to some value from before session\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "## Set the random seed values to regenerate the model.\n",
        "np.random.seed(0)\n",
        "rn.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClXAuoLushCd"
      },
      "source": [
        "metadata = dataset.columns[:4]\n",
        "# 4th index is the target variable\n",
        "continuous_ftrs = list(dataset.columns[5:27]) + list(dataset.columns[28:38])\n",
        "cat_ftrs = ['eatable',\n",
        "            'reordered_in_last_order',\n",
        "            'reordered_in_2ndlast_order',\n",
        "            'reordered_in_3rdlast_order']\n",
        "ftrs = continuous_ftrs + cat_ftrs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8y19YS0-shCe",
        "outputId": "60771193-7304-4941-c611-cc8582601f37"
      },
      "source": [
        "print('No. of continous ftrs:'.ljust(24),len(continuous_ftrs))\n",
        "print('No. of categorical ftrs:'.ljust(24),len(cat_ftrs))\n",
        "print('Total no. of ftrs:'.ljust(24),len(ftrs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of continous ftrs:   32\n",
            "No. of categorical ftrs: 4\n",
            "Total no. of ftrs:       36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QDMIV9K6WMQ"
      },
      "source": [
        "# tf_dataset_tr = tf.data.Dataset.from_tensor_slices(dataset.loc[dataset.eval_set=='train',ftrs])\n",
        "# taking lot of RAM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0ewHZNEoyei"
      },
      "source": [
        "def noise_adder(x_train,y_train):\n",
        "    '''Adds Gaussian noise to the input data.\n",
        "    1. Makes auto-encoder robust to noise.\n",
        "    2. Saves auto-encoder from overfitting.'''\n",
        "    noise_factor = 0.2\n",
        "    x_train_noisy = x_train + noise_factor * tf.random.normal(shape=x_train.shape,dtype=tf.float64) \n",
        "    x_train_noisy = tf.clip_by_value(x_train_noisy, clip_value_min=0., clip_value_max=1.,)\n",
        "    return x_train_noisy,y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaZGwtefQ4m0"
      },
      "source": [
        "def data_generator_tr():\n",
        "    '''Construct a data generator for tf.data.Dataset'''\n",
        "    data = dataset.loc[dataset.eval_set=='train',ftrs]\n",
        "    for row in data.itertuples(index=False, name=None):\n",
        "        yield row,row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9gACYeWy4du"
      },
      "source": [
        "def data_generator_cv():\n",
        "    '''Construct a data generator for tf.data.Dataset'''\n",
        "    data = dataset.loc[dataset.eval_set=='cv',ftrs]\n",
        "    for row in data.itertuples(index=False, name=None):\n",
        "        yield row,row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jPYxjBv5sXt"
      },
      "source": [
        "# setting different parameters\n",
        "train_len = (dataset.eval_set=='train').sum()\n",
        "cv_len = (dataset.eval_set=='cv').sum()\n",
        "epochs = 5\n",
        "batch_size = 32\n",
        "buffer_size_tr = 10000\n",
        "buffer_size_cv = 5000\n",
        "steps_per_epoch = np.ceil(train_len/batch_size)\n",
        "validation_steps = np.ceil(cv_len/batch_size)\n",
        "repeat_count = np.ceil((steps_per_epoch * epochs * batch_size) / train_len)    # repeat count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjePaBHkTI5L"
      },
      "source": [
        "tf_data_tr = tf.data.Dataset.from_generator(data_generator_tr,\n",
        "                                            output_signature=(tf.TensorSpec(shape=(36,), dtype=tf.float64),\n",
        "                                                               tf.TensorSpec(shape=(36,), dtype=tf.float64))\n",
        "                                            )\n",
        "\n",
        "tf_data_tr = tf_data_tr.map(noise_adder,num_parallel_calls=tf.data.AUTOTUNE)\\\n",
        "                        .shuffle(buffer_size_tr)\\\n",
        "                        .batch(batch_size,num_parallel_calls=tf.data.AUTOTUNE)\\\n",
        "                        .repeat(repeat_count)\\\n",
        "                        .prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In_W99XjliR5"
      },
      "source": [
        "tf_data_cv = tf.data.Dataset.from_generator(data_generator_cv,\n",
        "                                            output_signature=(tf.TensorSpec(shape=(36,), dtype=tf.float64),\n",
        "                                                               tf.TensorSpec(shape=(36,), dtype=tf.float64))\n",
        "                                            )\n",
        "\n",
        "# noise should not be added to the validation data or test data.\n",
        "# https://machinelearningmastery.com/train-neural-networks-with-noise-to-reduce-overfitting/#:~:text=Noise%20is%20only%20added%20during%20training.%20No%20noise%20is%20added%20during%20the%20evaluation%20of%20the%20model\n",
        "tf_data_cv = tf_data_cv.shuffle(buffer_size_cv)\\\n",
        "                        .batch(batch_size,num_parallel_calls=tf.data.AUTOTUNE)\\\n",
        "                        .prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hg4gHB08YNK0"
      },
      "source": [
        "# https://www.tensorflow.org/tutorials/generative/autoencoder\n",
        "latent_dim = 8\n",
        "\n",
        "class Autoencoder(Model):\n",
        "  def __init__(self, latent_dim):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.latent_dim = latent_dim\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      InputLayer(input_shape=(36,),name='l0'),                                 \n",
        "      Dense(16,activation='sigmoid',name='l1'),                     \n",
        "      Dense(latent_dim, activation='sigmoid',name='l2'),\n",
        "    ],name='encoder')\n",
        "\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      Dense(16,activation='sigmoid',name='l3'),   \n",
        "      Dense(36, activation='sigmoid',name='l4')\n",
        "    ],name='decoder')\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = Autoencoder(latent_dim)\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1R4227FyYQRd",
        "outputId": "999b8dfd-0f28-45b8-8c47-d3c153f9107a"
      },
      "source": [
        "autoencoder.fit(tf_data_tr,\n",
        "                validation_data=tf_data_cv,\n",
        "                epochs=epochs,\n",
        "                steps_per_epoch=steps_per_epoch,\n",
        "                validation_steps=validation_steps,\n",
        "                verbose=1,\n",
        "                use_multiprocessing=True,\n",
        "                workers=4\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "185291/185291 [==============================] - 1949s 10ms/step - loss: 0.0063 - val_loss: 0.0031\n",
            "Epoch 2/5\n",
            "185291/185291 [==============================] - 1843s 10ms/step - loss: 0.0046 - val_loss: 0.0025\n",
            "Epoch 3/5\n",
            "185291/185291 [==============================] - 1837s 10ms/step - loss: 0.0045 - val_loss: 0.0024\n",
            "Epoch 4/5\n",
            "185291/185291 [==============================] - 1861s 10ms/step - loss: 0.0045 - val_loss: 0.0022\n",
            "Epoch 5/5\n",
            "185291/185291 [==============================] - 1854s 10ms/step - loss: 0.0045 - val_loss: 0.0023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f157373f310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeTMTtpCbkiw",
        "outputId": "b59963a5-81db-4355-d6c9-89bdadafe127"
      },
      "source": [
        "# Save the entire model as a SavedModel.\n",
        "\"\"\"\n",
        "!mkdir -p saved_model\n",
        "autoencoder.save('saved_model/my_model')\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7U2Jv6ne8TC",
        "outputId": "94e12f3f-9eaa-4e54-b02b-0aa3e4dad5a2"
      },
      "source": [
        "\"\"\"\n",
        "!zip -r ./autoencoder.zip ./saved_model\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: saved_model/ (stored 0%)\n",
            "  adding: saved_model/my_model/ (stored 0%)\n",
            "  adding: saved_model/my_model/keras_metadata.pb (deflated 89%)\n",
            "  adding: saved_model/my_model/variables/ (stored 0%)\n",
            "  adding: saved_model/my_model/variables/variables.data-00000-of-00001 (deflated 20%)\n",
            "  adding: saved_model/my_model/variables/variables.index (deflated 65%)\n",
            "  adding: saved_model/my_model/saved_model.pb (deflated 89%)\n",
            "  adding: saved_model/my_model/assets/ (stored 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oziVJBRfW3e",
        "outputId": "3df33e65-02cd-4e69-eaa1-e22dc648a532"
      },
      "source": [
        "!unzip ./autoencoder.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./autoencoder.zip\n",
            "   creating: saved_model/\n",
            "   creating: saved_model/my_model/\n",
            "  inflating: saved_model/my_model/keras_metadata.pb  \n",
            "   creating: saved_model/my_model/variables/\n",
            "  inflating: saved_model/my_model/variables/variables.data-00000-of-00001  \n",
            "  inflating: saved_model/my_model/variables/variables.index  \n",
            "  inflating: saved_model/my_model/saved_model.pb  \n",
            "   creating: saved_model/my_model/assets/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttt25C9Hdbe5",
        "outputId": "89d95440-1ac0-498f-97d4-2b0ae490c959"
      },
      "source": [
        "autoencoder = tf.keras.models.load_model('saved_model/my_model')\n",
        "\n",
        "# Check its architecture\n",
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder (Sequential)         (None, 8)                 728       \n",
            "_________________________________________________________________\n",
            "decoder (Sequential)         (None, 36)                756       \n",
            "=================================================================\n",
            "Total params: 1,484\n",
            "Trainable params: 1,484\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1smqgBQ_Af1",
        "outputId": "2bb582fd-06ce-4b6d-c918-4801ced1ef3f"
      },
      "source": [
        "autoencoder.encoder.summary()\n",
        "autoencoder.decoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "l1 (Dense)                   (None, 16)                592       \n",
            "_________________________________________________________________\n",
            "l2 (Dense)                   (None, 8)                 136       \n",
            "=================================================================\n",
            "Total params: 728\n",
            "Trainable params: 728\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "l3 (Dense)                   (None, 16)                144       \n",
            "_________________________________________________________________\n",
            "l4 (Dense)                   (None, 36)                612       \n",
            "=================================================================\n",
            "Total params: 756\n",
            "Trainable params: 756\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifq48F4gid7v"
      },
      "source": [
        "encoded_ftrs = autoencoder.encoder.predict(dataset[ftrs])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd3pr6z_26Bo"
      },
      "source": [
        "enc_ftr_names = ['enc1','enc2','enc3','enc4','enc5','enc6','enc7','enc8']\n",
        "dataset[enc_ftr_names] = encoded_ftrs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDWpwHsFmtz9",
        "outputId": "e2696bb2-00c1-4288-be39-c44f47913d58"
      },
      "source": [
        "dataset.info(memory_usage='deep')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13307953 entries, 0 to 13307952\n",
            "Data columns (total 49 columns):\n",
            " #   Column                        Dtype   \n",
            "---  ------                        -----   \n",
            " 0   user_id                       uint32  \n",
            " 1   product_id                    uint16  \n",
            " 2   order_id                      uint32  \n",
            " 3   eval_set                      category\n",
            " 4   reordered                     float16 \n",
            " 5   #reorders_u                   float64 \n",
            " 6   #purchases_u                  float64 \n",
            " 7   #first_purchases_u            float64 \n",
            " 8   p(reorder|user)               float64 \n",
            " 9   mean_#reorders                float64 \n",
            " 10  median_#reorders              float64 \n",
            " 11  min_#reorders                 float64 \n",
            " 12  max_#reorders                 float64 \n",
            " 13  mean_#purchases               float64 \n",
            " 14  median_#purchases             float64 \n",
            " 15  min_#purchases                float64 \n",
            " 16  max_#purchases                float64 \n",
            " 17  mean_#first_purchases         float64 \n",
            " 18  median_#first_purchases       float64 \n",
            " 19  min_#first_purchases          float64 \n",
            " 20  max_#first_purchases          float64 \n",
            " 21  mean_p(reorder|user,order)    float64 \n",
            " 22  median_p(reorder|user,order)  float64 \n",
            " 23  min_p(reorder|user,order)     float64 \n",
            " 24  max_p(reorder|user,order)     float64 \n",
            " 25  dep_target_enc                float64 \n",
            " 26  aisle_target_enc              float64 \n",
            " 27  eatable                       uint8   \n",
            " 28  #avg_reorders_dep             float64 \n",
            " 29  p(reorder|dep_of_prod)        float64 \n",
            " 30  #avg_reorders_aisle           float64 \n",
            " 31  p(reorder|aisle_of_prod)      float64 \n",
            " 32  #reorders_p                   float64 \n",
            " 33  #purchases_p                  float64 \n",
            " 34  #first_purchases_p            float64 \n",
            " 35  p(reorder|product)            float64 \n",
            " 36  #reorders_up                  float64 \n",
            " 37  p(reorder|user,product)       float64 \n",
            " 38  reordered_in_last_order       uint8   \n",
            " 39  reordered_in_2ndlast_order    uint8   \n",
            " 40  reordered_in_3rdlast_order    uint8   \n",
            " 41  enc1                          float32 \n",
            " 42  enc2                          float32 \n",
            " 43  enc3                          float32 \n",
            " 44  enc4                          float32 \n",
            " 45  enc5                          float32 \n",
            " 46  enc6                          float32 \n",
            " 47  enc7                          float32 \n",
            " 48  enc8                          float32 \n",
            "dtypes: category(1), float16(1), float32(8), float64(32), uint16(1), uint32(2), uint8(4)\n",
            "memory usage: 3.8 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YHIjH1_e6le",
        "outputId": "6ac8fb68-0c0b-4a5e-ffc7-647fcc52746e"
      },
      "source": [
        "%%time\n",
        "# Saving dataset locally\n",
        "dataset.to_feather('dataset.feather')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 8.96 s, sys: 1.46 s, total: 10.4 s\n",
            "Wall time: 4.09 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCCWs17rekbx",
        "outputId": "f5fa1810-223a-469a-87ad-05466930d585"
      },
      "source": [
        "kaggle_file_uploader(files = ['/content/dataset.feather'],\n",
        "                     folder='data',\n",
        "                     id = 'shubhamscifi/instacart',\n",
        "                     title = 'instacart',\n",
        "                     msg='demo',\n",
        "                     first_time=False,\n",
        "                     del_after_upload=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data package template written to: data/dataset-metadata.json\n",
            "Starting upload for file dataset.feather\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "100% 0.99G/0.99G [00:10<00:00, 106MB/s]\n",
            "Upload successful: dataset.feather (1009MB)\n",
            "Starting upload for file dataset-prev.feather\n",
            "100% 603M/603M [00:06<00:00, 96.1MB/s]\n",
            "Upload successful: dataset-prev.feather (603MB)\n",
            "Dataset version is being created. Please check progress at /api/v1/datasets/status/shubhamscifi/instacart\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JjjGRURe6mM"
      },
      "source": [
        "metadata = dataset.columns[:4]\n",
        "# 4th index is the target variable\n",
        "continuous_ftrs = list(dataset.columns[5:27]) + list(dataset.columns[28:38]) + list(dataset.columns[41:49])\n",
        "cat_ftrs = ['eatable',\n",
        "            'reordered_in_last_order',\n",
        "            'reordered_in_2ndlast_order',\n",
        "            'reordered_in_3rdlast_order']\n",
        "ftrs = continuous_ftrs + cat_ftrs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43HkFV6De6mN",
        "outputId": "06f9fb07-a864-4bdc-c4ea-c91cca2073bb"
      },
      "source": [
        "print('No. of continous ftrs:'.ljust(24),len(continuous_ftrs))\n",
        "print('No. of categorical ftrs:'.ljust(24),len(cat_ftrs))\n",
        "print('Total no. of ftrs:'.ljust(24),len(ftrs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of continous ftrs:   40\n",
            "No. of categorical ftrs: 4\n",
            "Total no. of ftrs:       44\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_uNiq1Igqhg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN7ZopaEYpyd"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}